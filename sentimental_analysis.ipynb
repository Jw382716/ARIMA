{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNUPdm6JNlZ6qSTfFIcgGvp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jw382716/ARIMA/blob/main/sentimental_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-Fp9QnT323N",
        "outputId": "9e53335e-fe29-4586-809a-ce7425da2d0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        " import os\n",
        "current_path = os.getcwd()\n",
        "print(current_path)\n",
        "# 구글 코랩 드라이브 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "DATA_IN_PATH = '/content/drive/MyDrive/DeepLearning_NLP/data_in/'\n",
        "file_list = ['labeledTrainData.tsv.zip', 'unlabeledTrainData.tsv.zip', 'testData.tsv.zip']\n",
        "\n",
        "for file in file_list :\n",
        "  zipRef = zipfile.ZipFile(DATA_IN_PATH + file, 'r')\n",
        "  zipRef.extractall(DATA_IN_PATH)\n",
        "  zipRef.close()"
      ],
      "metadata": {
        "id": "p2-gM-9D5aST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "print(\"파일크기 : \")\n",
        "for file in os.listdir(DATA_IN_PATH) :\n",
        "  if 'tsv' in file and 'zip' not in file :\n",
        "    print(file.ljust(30) + str(round(os.path.getsize(DATA_IN_PATH + file) / 1000000,2)) + 'MB')\n",
        "  \n",
        "train_data = pd.read_csv(DATA_IN_PATH + 'labeledTrainData.tsv', header = 0, delimiter = '\\t', quoting = 3)\n",
        "train_data.head()\n",
        "\n",
        "print('전체 학습데이터의 개수 : {}'.format(len(train_data)))\n",
        "\n",
        "train_length = train_data['review'].apply(len)\n",
        "train_length.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGwV4TCT8Asb",
        "outputId": "ddb13bca-895d-4c71-ffb3-7a1fa36ee36e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "파일크기 : \n",
            "unlabeledTrainData.tsv        67.28MB\n",
            "testData.tsv                  32.72MB\n",
            "labeledTrainData.tsv          33.56MB\n",
            "전체 학습데이터의 개수 : 25000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    2304\n",
              "1     948\n",
              "2    2451\n",
              "3    2247\n",
              "4    2233\n",
              "Name: review, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re \n",
        "import json \n",
        "import pandas as pd \n",
        "import numpy as np \n",
        "import nltk \n",
        "from bs4 import BeautifulSoup \n",
        "from nltk.corpus import stopwords \n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences    \n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "DATA_IN_PATH = '/content/drive/MyDrive/DeepLearning_NLP/data_in/'\n",
        "train_data = pd.read_csv(DATA_IN_PATH + 'labeledTrainData.tsv', header = 0, delimiter = '\\t', quoting = 3)\n",
        "\n",
        "review = train_data['review'][0]\n",
        "review_text = BeautifulSoup(review, \"html5lib\").get_text()\n",
        "review_text = re.sub('[^a-zA-Z]', ' ', review_text)\n",
        "review_text = review_text.lower()\n",
        "words = review_text.split()\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "words = [w for w in words if not w in stop_words]\n",
        "print(words)\n",
        "clean_review = ' '.join(words)\n",
        "print(clean_review)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXs2Ggh2BHQJ",
        "outputId": "0f210832-4281-4c63-e9f7-60767c228db4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['stuff', 'going', 'moment', 'mj', 'started', 'listening', 'music', 'watching', 'odd', 'documentary', 'watched', 'wiz', 'watched', 'moonwalker', 'maybe', 'want', 'get', 'certain', 'insight', 'guy', 'thought', 'really', 'cool', 'eighties', 'maybe', 'make', 'mind', 'whether', 'guilty', 'innocent', 'moonwalker', 'part', 'biography', 'part', 'feature', 'film', 'remember', 'going', 'see', 'cinema', 'originally', 'released', 'subtle', 'messages', 'mj', 'feeling', 'towards', 'press', 'also', 'obvious', 'message', 'drugs', 'bad', 'kay', 'visually', 'impressive', 'course', 'michael', 'jackson', 'unless', 'remotely', 'like', 'mj', 'anyway', 'going', 'hate', 'find', 'boring', 'may', 'call', 'mj', 'egotist', 'consenting', 'making', 'movie', 'mj', 'fans', 'would', 'say', 'made', 'fans', 'true', 'really', 'nice', 'actual', 'feature', 'film', 'bit', 'finally', 'starts', 'minutes', 'excluding', 'smooth', 'criminal', 'sequence', 'joe', 'pesci', 'convincing', 'psychopathic', 'powerful', 'drug', 'lord', 'wants', 'mj', 'dead', 'bad', 'beyond', 'mj', 'overheard', 'plans', 'nah', 'joe', 'pesci', 'character', 'ranted', 'wanted', 'people', 'know', 'supplying', 'drugs', 'etc', 'dunno', 'maybe', 'hates', 'mj', 'music', 'lots', 'cool', 'things', 'like', 'mj', 'turning', 'car', 'robot', 'whole', 'speed', 'demon', 'sequence', 'also', 'director', 'must', 'patience', 'saint', 'came', 'filming', 'kiddy', 'bad', 'sequence', 'usually', 'directors', 'hate', 'working', 'one', 'kid', 'let', 'alone', 'whole', 'bunch', 'performing', 'complex', 'dance', 'scene', 'bottom', 'line', 'movie', 'people', 'like', 'mj', 'one', 'level', 'another', 'think', 'people', 'stay', 'away', 'try', 'give', 'wholesome', 'message', 'ironically', 'mj', 'bestest', 'buddy', 'movie', 'girl', 'michael', 'jackson', 'truly', 'one', 'talented', 'people', 'ever', 'grace', 'planet', 'guilty', 'well', 'attention', 'gave', 'subject', 'hmmm', 'well', 'know', 'people', 'different', 'behind', 'closed', 'doors', 'know', 'fact', 'either', 'extremely', 'nice', 'stupid', 'guy', 'one', 'sickest', 'liars', 'hope', 'latter']\n",
            "stuff going moment mj started listening music watching odd documentary watched wiz watched moonwalker maybe want get certain insight guy thought really cool eighties maybe make mind whether guilty innocent moonwalker part biography part feature film remember going see cinema originally released subtle messages mj feeling towards press also obvious message drugs bad kay visually impressive course michael jackson unless remotely like mj anyway going hate find boring may call mj egotist consenting making movie mj fans would say made fans true really nice actual feature film bit finally starts minutes excluding smooth criminal sequence joe pesci convincing psychopathic powerful drug lord wants mj dead bad beyond mj overheard plans nah joe pesci character ranted wanted people know supplying drugs etc dunno maybe hates mj music lots cool things like mj turning car robot whole speed demon sequence also director must patience saint came filming kiddy bad sequence usually directors hate working one kid let alone whole bunch performing complex dance scene bottom line movie people like mj one level another think people stay away try give wholesome message ironically mj bestest buddy movie girl michael jackson truly one talented people ever grace planet guilty well attention gave subject hmmm well know people different behind closed doors know fact either extremely nice stupid guy one sickest liars hope latter\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing(review, remove_stopwords = False) :\n",
        "  review_text = BeautifulSoup(review, \"html5lib\").get_text()\n",
        "  review_text = re.sub('[^a-zA-Z]', ' ', review_text)\n",
        "  review_text = review_text.lower()\n",
        "  if remove_stopwords :\n",
        "    words = review_text.split()\n",
        "    stops = set(stopwords.words('english'))\n",
        "    words = [w for w in words if not w in stops]\n",
        "    review_text = ' '.join(words)\n",
        "  return review_text\n",
        "\n",
        "clean_train_reviews = []\n",
        "for review in train_data['review'] :\n",
        "  clean_train_reviews.append(preprocessing(review, remove_stopwords = True))\n",
        "clean_train_df = pd.DataFrame({'review' : clean_train_reviews,\n",
        "                               'sentiment' : train_data['sentiment']})"
      ],
      "metadata": {
        "id": "lmX4iC_UTUFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(clean_train_reviews)\n",
        "text_sequences = tokenizer.texts_to_sequences(clean_train_reviews)\n",
        "\n",
        "MAX_SEQUENCE_LENGTH = 174\n",
        "train_inputs = pad_sequences(text_sequences, maxlen = MAX_SEQUENCE_LENGTH, padding = 'post')\n",
        "print('Train Data :', train_inputs.shape)\n",
        "\n",
        "train_labels = np.array(train_data['sentiment'])\n",
        "print('Label:',train_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEGLvYUCU0Hu",
        "outputId": "1ad9c18e-0412-48ac-babf-c75722fc2bbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data : (25000, 174)\n",
            "Label: (25000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "reviews = list(train_data['review'])\n",
        "sentiments = list(train_data['sentiment'])\n",
        "vectorizer = TfidfVectorizer(min_df = 0.0, analyzer = 'char', sublinear_tf=True, ngram_range=(1,3), max_features=5000)\n",
        "x = vectorizer.fit_transform(reviews)\n",
        "y = np.array(sentiments)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.2, random_state = 42)\n",
        "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
        "lgs = LogisticRegression(class_weight = 'balanced')\n",
        "lgs.fit(x_train, y_train)\n",
        "print('Accuracy : %f'% lgs.score(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctSgzzyTWlMp",
        "outputId": "0020b465-427a-46f0-8aae-6711cddca056"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20000, 5000) (5000, 5000) (20000,) (5000,)\n",
            "Accuracy : 0.869600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Dense\n",
        "x_train1 = x_train.toarray()\n",
        "x_test1 = x_test.toarray()\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(Dense(5000, activation = 'relu'))\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "model.compile(loss = \"accuracy\")\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "ckkQYgt-jOwC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "5da33f91-e993-4de9-ffc4-6a043c253886"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-7ca8de4c3a30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, line_length, positions, print_fn, expand_nested, show_trainable)\u001b[0m\n\u001b[1;32m   2774\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2775\u001b[0m       raise ValueError(\n\u001b[0;32m-> 2776\u001b[0;31m           \u001b[0;34m'This model has not yet been built. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2777\u001b[0m           \u001b[0;34m'Build the model first by calling `build()` or by calling '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2778\u001b[0m           'the model on a batch of data.')\n",
            "\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8FtEHp6JMg_8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}